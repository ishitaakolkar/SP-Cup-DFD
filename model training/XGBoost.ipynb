{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRoAa0YB-Pdc",
        "outputId": "e3f9acc0-a069-4ba4-de74-ff202661dc03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading features...\n",
            "Validating and extracting features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating and extracting features: 100%|██████████| 16/16 [00:00<00:00, 652.99it/s]\n",
            "Validating and extracting features: 100%|██████████| 17090/17090 [00:00<00:00, 1472849.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combining features and labels...\n",
            "Normalizing features...\n",
            "Splitting dataset into training and validation sets...\n",
            "Computing class weights...\n",
            "Training XGBoost model with multithreading and GPU utilization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [11:09:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [11:09:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving trained model...\n",
            "Model saved to drive/MyDrive/SP_cup/landmark_model.joblib\n",
            "Evaluating the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [11:09:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [11:09:13] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      3418\n",
            "         1.0       1.00      1.00      1.00     21943\n",
            "\n",
            "    accuracy                           1.00     25361\n",
            "   macro avg       1.00      1.00      1.00     25361\n",
            "weighted avg       1.00      1.00      1.00     25361\n",
            "\n",
            "Validation Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Paths to pre-extracted features\n",
        "FAKE_TRAIN_FEATURES_PATH = 'drive/MyDrive/SP_cup/features/standardized_fake_train.pkl'\n",
        "REAL_TRAIN_FEATURES_PATH = 'drive/MyDrive/SP_cup/features/standardized_real_train.pkl'\n",
        "OUTPUT_MODEL_PATH = 'drive/MyDrive/SP_cup/landmark_model.joblib'\n",
        "RANDOM_STATE = 52\n",
        "\n",
        "# Configure GPU for TensorFlow\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "# Function to load features from file\n",
        "def load_features(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# Validate and extract valid feature vectors\n",
        "def validate_and_extract(features):\n",
        "    valid_features = []\n",
        "    for entry in tqdm(features, desc=\"Validating and extracting features\"):\n",
        "        if isinstance(entry, list):\n",
        "            valid_features.extend(\n",
        "                [sub_entry['features'] for sub_entry in entry if isinstance(sub_entry, dict) and 'features' in sub_entry]\n",
        "            )\n",
        "        elif isinstance(entry, dict) and 'features' in entry:\n",
        "            valid_features.append(entry['features'])\n",
        "    return np.array(valid_features, dtype=np.float32)\n",
        "\n",
        "# Load and process fake and real features\n",
        "print(\"Loading features...\")\n",
        "fake_features = load_features(FAKE_TRAIN_FEATURES_PATH)\n",
        "real_features = load_features(REAL_TRAIN_FEATURES_PATH)\n",
        "\n",
        "# Validate and extract features\n",
        "print(\"Validating and extracting features...\")\n",
        "X_fake = validate_and_extract(fake_features)\n",
        "X_real = validate_and_extract(real_features)\n",
        "\n",
        "# Create labels\n",
        "y_fake = np.ones(len(X_fake))  # Fake class label (1)\n",
        "y_real = np.zeros(len(X_real))  # Real class label (0)\n",
        "\n",
        "# Combine features and labels\n",
        "print(\"Combining features and labels...\")\n",
        "X_all = np.vstack((X_fake, X_real))  # Combine both features\n",
        "y_all = np.hstack((y_fake, y_real))  # Combine labels for both\n",
        "\n",
        "# Normalize features\n",
        "print(\"Normalizing features...\")\n",
        "scaler = StandardScaler()\n",
        "X_all = scaler.fit_transform(X_all)\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "print(\"Splitting dataset into training and validation sets...\")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_all, y_all, test_size=0.2, random_state=RANDOM_STATE, stratify=y_all\n",
        ")\n",
        "\n",
        "# Compute class weights\n",
        "print(\"Computing class weights...\")\n",
        "class_weight_dict = {0: len(y_train) / np.sum(y_train == 0), 1: len(y_train) / np.sum(y_train == 1)}\n",
        "\n",
        "# Train the XGBoost model\n",
        "def train_model(X_train, y_train, class_weight_dict):\n",
        "    print(\"Training XGBoost model with multithreading and GPU utilization...\")\n",
        "    model = XGBClassifier(\n",
        "        scale_pos_weight=class_weight_dict[0] / class_weight_dict[1],\n",
        "        tree_method=\"gpu_hist\",  # Use GPU for training\n",
        "        predictor=\"gpu_predictor\",\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1  # Use all available CPU threads for data preparation\n",
        "    )\n",
        "    model.fit(X_train, y_train, sample_weight=np.array([class_weight_dict[label] for label in y_train]))\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(X_train, y_train, class_weight_dict)\n",
        "\n",
        "# Save the trained model\n",
        "print(\"Saving trained model...\")\n",
        "joblib.dump(model, OUTPUT_MODEL_PATH)\n",
        "print(f\"Model saved to {OUTPUT_MODEL_PATH}\")\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_val, y_val):\n",
        "    print(\"Evaluating the model...\")\n",
        "    y_pred = model.predict(X_val)\n",
        "    print(\"Classification Report:\")\n",
        "    from sklearn.metrics import classification_report, accuracy_score\n",
        "    print(classification_report(y_val, y_pred))\n",
        "    print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
        "\n",
        "evaluate_model(model, X_val, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download the shape predictor file\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "\n",
        "# Step 2: Extract the downloaded bz2 file\n",
        "!bunzip2 shape_predictor_68_face_landmarks.dat.bz2\n",
        "\n",
        "# Step 3: Set the correct path to the downloaded file\n",
        "predictor_path = '/content/shape_predictor_68_face_landmarks.dat'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-qu_jPkRRuN",
        "outputId": "a2a45fa1-a531-4c68-94fa-851c8d858945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-19 11:14:06--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  78.7MB/s    in 0.8s    \n",
            "\n",
            "2025-01-19 11:14:07 (78.7 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import joblib\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load pre-saved data (Landmarks and Spatial Features)\n",
        "print(\"Loading facial landmarks...\")\n",
        "with open('drive/MyDrive/SP_cup/fake_valid_landmarks.pkl', 'rb') as f:\n",
        "    fake_valid_landmarks = pickle.load(f)\n",
        "\n",
        "with open('drive/MyDrive/SP_cup/real_valid_landmarks.pkl', 'rb') as f:\n",
        "    real_valid_landmarks = pickle.load(f)\n",
        "\n",
        "# Labels: Fake = 0, Real = 1\n",
        "fake_valid_labels = [1] * len(fake_valid_landmarks)\n",
        "real_valid_labels = [0] * len(real_valid_landmarks)\n",
        "\n",
        "# Load spatial features from pickle files\n",
        "print(\"Loading spatial features...\")\n",
        "with open('drive/MyDrive/SP_cup/features/spatial_valid_fake.pkl', 'rb') as f:\n",
        "    fake_spatial_features = pickle.load(f)\n",
        "\n",
        "with open('drive/MyDrive/SP_cup/features/spatial_valid_real.pkl', 'rb') as f:\n",
        "    real_spatial_features = pickle.load(f)\n",
        "\n",
        "# Ensure spatial features match the number of images (after filtering None values)\n",
        "if len(fake_spatial_features) != len(fake_valid_landmarks):\n",
        "    print(f\"Warning: Mismatch between number of fake images and spatial features: {len(fake_spatial_features)} vs {len(fake_valid_landmarks)}\")\n",
        "    fake_spatial_features = [fake_spatial_features[i] for i in range(len(fake_valid_landmarks)) if fake_valid_landmarks[i] is not None]\n",
        "\n",
        "if len(real_spatial_features) != len(real_valid_landmarks):\n",
        "    print(f\"Warning: Mismatch between number of real images and spatial features: {len(real_spatial_features)} vs {len(real_valid_landmarks)}\")\n",
        "    real_spatial_features = [real_spatial_features[i] for i in range(len(real_valid_landmarks)) if real_valid_landmarks[i] is not None]\n",
        "\n",
        "# Combine facial landmarks and spatial features\n",
        "print(\"Combining facial landmarks and spatial features...\")\n",
        "combined_features = []\n",
        "\n",
        "# Function to ensure landmarks and spatial features are valid arrays\n",
        "def ensure_valid_array(data):\n",
        "    if isinstance(data, np.ndarray):\n",
        "        return data.flatten()  # Flatten the array to 1D\n",
        "    else:\n",
        "        return np.array(data).flatten()  # Ensure it's an array and flatten\n",
        "\n",
        "# Combine features for fake images\n",
        "for lm, spatial in zip(fake_valid_landmarks, fake_spatial_features):\n",
        "    if lm is not None and spatial is not None:\n",
        "        lm = ensure_valid_array(lm)\n",
        "        spatial = spatial.get('features', None)  # Extract the features array from the dictionary\n",
        "        if spatial is not None:\n",
        "            spatial = ensure_valid_array(spatial)\n",
        "            if len(lm) > 0 and len(spatial) > 0:\n",
        "                combined_features.append(np.concatenate([lm, spatial]))\n",
        "\n",
        "# Combine features for real images\n",
        "for lm, spatial in zip(real_valid_landmarks, real_spatial_features):\n",
        "    if lm is not None and spatial is not None:\n",
        "        lm = ensure_valid_array(lm)\n",
        "        spatial = spatial.get('features', None)  # Extract the features array from the dictionary\n",
        "        if spatial is not None:\n",
        "            spatial = ensure_valid_array(spatial)\n",
        "            if len(lm) > 0 and len(spatial) > 0:\n",
        "                combined_features.append(np.concatenate([lm, spatial]))\n",
        "\n",
        "# Convert to numpy array and ensure correct data type\n",
        "try:\n",
        "    combined_features = np.array(combined_features, dtype=np.float32)\n",
        "    print(f\"Combined features shape: {combined_features.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during conversion to numpy array: {e}\")\n",
        "\n",
        "# Combine labels\n",
        "combined_labels = np.array(fake_valid_labels + real_valid_labels, dtype=np.int32)\n",
        "\n",
        "# Ensure the combined features have the same number of columns as expected by the model\n",
        "expected_num_features = 1280  # Number of features the model expects\n",
        "if combined_features.shape[1] > expected_num_features:\n",
        "    combined_features = combined_features[:, :expected_num_features]\n",
        "    print(f\"Trimmed combined features shape: {combined_features.shape}\")\n",
        "elif combined_features.shape[1] < expected_num_features:\n",
        "    print(f\"Warning: Combined features have fewer than {expected_num_features} features. Model might not work as expected.\")\n",
        "\n",
        "# Load model\n",
        "print(\"Loading model...\")\n",
        "model = joblib.load('drive/MyDrive/SP_cup/landmark_model.joblib')\n",
        "\n",
        "# Predict\n",
        "print(\"Predicting on validation data...\")\n",
        "y_pred_proba = model.predict_proba(combined_features)[:, 1]  # Get probabilities for class 1\n",
        "\n",
        "# Adjust threshold for prediction (example: threshold at 0.3 for higher recall)\n",
        "threshold = 0.4\n",
        "y_pred = (y_pred_proba > threshold).astype(int)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Evaluating model...\")\n",
        "print(classification_report(combined_labels, y_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(combined_labels, y_pred):.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(combined_labels, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "v0g_aTXgAVmi",
        "outputId": "02399d00-6385-4261-e827-0fd17e35c8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading facial landmarks...\n",
            "Loading spatial features...\n",
            "Warning: Mismatch between number of fake images and spatial features: 1524 vs 1523\n",
            "Warning: Mismatch between number of real images and spatial features: 1548 vs 1544\n",
            "Combining facial landmarks and spatial features...\n",
            "Combined features shape: (3067, 1416)\n",
            "Trimmed combined features shape: (3067, 1280)\n",
            "Loading model...\n",
            "Predicting on validation data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:13:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      1.00      0.67      1544\n",
            "           1       0.78      0.01      0.02      1523\n",
            "\n",
            "    accuracy                           0.51      3067\n",
            "   macro avg       0.64      0.50      0.34      3067\n",
            "weighted avg       0.64      0.51      0.35      3067\n",
            "\n",
            "Validation Accuracy: 0.5067\n",
            "Confusion Matrix:\n",
            "[[1540    4]\n",
            " [1509   14]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import joblib\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load pre-saved data (Landmarks and Spatial Features)\n",
        "print(\"Loading facial landmarks...\")\n",
        "with open('drive/MyDrive/SP_cup/fake_valid_landmarks.pkl', 'rb') as f:\n",
        "    fake_valid_landmarks = pickle.load(f)\n",
        "\n",
        "with open('drive/MyDrive/SP_cup/real_valid_landmarks.pkl', 'rb') as f:\n",
        "    real_valid_landmarks = pickle.load(f)\n",
        "\n",
        "# Labels: Fake = 0, Real = 1\n",
        "fake_valid_labels = [0] * len(fake_valid_landmarks)\n",
        "real_valid_labels = [1] * len(real_valid_landmarks)\n",
        "\n",
        "# Load spatial features from pickle files\n",
        "print(\"Loading spatial features...\")\n",
        "with open('drive/MyDrive/SP_cup/features/spatial_valid_fake.pkl', 'rb') as f:\n",
        "    fake_spatial_features = pickle.load(f)\n",
        "\n",
        "with open('drive/MyDrive/SP_cup/features/spatial_valid_real.pkl', 'rb') as f:\n",
        "    real_spatial_features = pickle.load(f)\n",
        "\n",
        "# Combine facial landmarks and spatial features\n",
        "print(\"Combining facial landmarks and spatial features...\")\n",
        "\n",
        "# Function to ensure landmarks and spatial features are valid arrays\n",
        "def ensure_valid_array(data):\n",
        "    if isinstance(data, np.ndarray):\n",
        "        return data.flatten()  # Flatten the array to 1D\n",
        "    else:\n",
        "        return np.array(data).flatten()  # Ensure it's an array and flatten\n",
        "\n",
        "combined_features = []\n",
        "\n",
        "# Combine features for fake images\n",
        "for lm, spatial in zip(fake_valid_landmarks, fake_spatial_features):\n",
        "    if lm is not None and spatial is not None:\n",
        "        lm = ensure_valid_array(lm)\n",
        "        spatial = spatial.get('features', None)  # Extract the features array from the dictionary\n",
        "        if spatial is not None:\n",
        "            spatial = ensure_valid_array(spatial)\n",
        "            if len(lm) > 0 and len(spatial) > 0:\n",
        "                combined_features.append(np.concatenate([lm, spatial]))\n",
        "\n",
        "# Combine features for real images\n",
        "for lm, spatial in zip(real_valid_landmarks, real_spatial_features):\n",
        "    if lm is not None and spatial is not None:\n",
        "        lm = ensure_valid_array(lm)\n",
        "        spatial = spatial.get('features', None)  # Extract the features array from the dictionary\n",
        "        if spatial is not None:\n",
        "            spatial = ensure_valid_array(spatial)\n",
        "            if len(lm) > 0 and len(spatial) > 0:\n",
        "                combined_features.append(np.concatenate([lm, spatial]))\n",
        "\n",
        "# Convert to numpy array\n",
        "combined_features = np.array(combined_features, dtype=np.float32)\n",
        "\n",
        "# Combine labels\n",
        "combined_labels = np.array(fake_valid_labels + real_valid_labels, dtype=np.int32)\n",
        "\n",
        "# Resampling with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(combined_features, combined_labels)\n",
        "\n",
        "# Define the hyperparameters for XGBoost\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'booster': 'gbtree',\n",
        "    'max_depth': 5,  # You can tune this\n",
        "    'learning_rate': 0.1,  # You can tune this\n",
        "    'n_estimators': 100,  # You can tune this\n",
        "    'subsample': 0.8,  # You can tune this\n",
        "    'colsample_bytree': 0.8,  # You can tune this\n",
        "    'gamma': 0.1,  # You can tune this\n",
        "    'random_state': 52\n",
        "}\n",
        "\n",
        "# Prepare the DMatrix for XGBoost\n",
        "dtrain = xgb.DMatrix(X_resampled, label=y_resampled)\n",
        "\n",
        "# Perform Cross-validation with hyperparameter tuning\n",
        "cv_results = xgb.cv(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=5,\n",
        "    nfold=3,\n",
        "    metrics=['error', 'logloss'],\n",
        "    early_stopping_rounds=5,\n",
        "    verbose_eval=True\n",
        ")\n",
        "\n",
        "# Print the results\n",
        "print(\"Cross-validation results:\")\n",
        "print(cv_results)\n",
        "\n",
        "# Best iteration from cross-validation (based on evaluation metrics)\n",
        "best_iteration = cv_results['test-logloss-mean'].idxmin()\n",
        "\n",
        "# Train the final model using the best parameters\n",
        "final_model = xgb.train(params, dtrain, num_boost_round=best_iteration)\n",
        "\n",
        "# Save the final model\n",
        "joblib.dump(final_model, 'best_landmark_model.xgb')\n",
        "\n",
        "# Predict using the final model\n",
        "print(\"Predicting on validation data...\")\n",
        "y_pred = final_model.predict(xgb.DMatrix(X_resampled))\n",
        "y_pred = np.round(y_pred)  # Round to get binary predictions (0 or 1)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating model...\")\n",
        "print(classification_report(y_resampled, y_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_resampled, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfZQh2q2d94U",
        "outputId": "a45ff295-0ee1-4750-d6b8-c8e121437f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading facial landmarks...\n",
            "Loading spatial features...\n",
            "Combining facial landmarks and spatial features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:18:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:18:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-error:0.05716+0.00577\ttrain-logloss:0.61528+0.00180\ttest-error:0.09586+0.01081\ttest-logloss:0.62289+0.00142\n",
            "[1]\ttrain-error:0.05068+0.00692\ttrain-logloss:0.55437+0.00187\ttest-error:0.08582+0.01336\ttest-logloss:0.56620+0.00318\n",
            "[2]\ttrain-error:0.03562+0.00166\ttrain-logloss:0.49991+0.00255\ttest-error:0.06541+0.00563\ttest-logloss:0.51647+0.00413\n",
            "[3]\ttrain-error:0.02996+0.00256\ttrain-logloss:0.45068+0.00240\ttest-error:0.05959+0.00485\ttest-logloss:0.47075+0.00344\n",
            "[4]\ttrain-error:0.02526+0.00458\ttrain-logloss:0.40813+0.00138\ttest-error:0.05732+0.00755\ttest-logloss:0.43172+0.00298\n",
            "Cross-validation results:\n",
            "   train-error-mean  train-error-std  train-logloss-mean  train-logloss-std  \\\n",
            "0          0.057156         0.005769            0.615285           0.001796   \n",
            "1          0.050679         0.006920            0.554375           0.001867   \n",
            "2          0.035622         0.001659            0.499912           0.002547   \n",
            "3          0.029955         0.002557            0.450680           0.002397   \n",
            "4          0.025260         0.004580            0.408135           0.001376   \n",
            "\n",
            "   test-error-mean  test-error-std  test-logloss-mean  test-logloss-std  \n",
            "0         0.095860        0.010810           0.622890          0.001417  \n",
            "1         0.085822        0.013362           0.566201          0.003183  \n",
            "2         0.065415        0.005634           0.516474          0.004128  \n",
            "3         0.059586        0.004853           0.470746          0.003437  \n",
            "4         0.057317        0.007554           0.431723          0.002981  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:18:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting on validation data...\n",
            "Evaluating model...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97      1544\n",
            "           1       0.96      0.98      0.97      1544\n",
            "\n",
            "    accuracy                           0.97      3088\n",
            "   macro avg       0.97      0.97      0.97      3088\n",
            "weighted avg       0.97      0.97      0.97      3088\n",
            "\n",
            "Validation Accuracy: 0.9660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import joblib\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load pre-saved data (Landmarks and Spatial Features)\n",
        "print(\"Loading facial landmarks...\")\n",
        "with open('drive/MyDrive/SP_cup/fake_valid_landmarks.pkl', 'rb') as f:\n",
        "    fake_valid_landmarks = pickle.load(f)\n",
        "\n",
        "with open('drive/MyDrive/SP_cup/real_valid_landmarks.pkl', 'rb') as f:\n",
        "    real_valid_landmarks = pickle.load(f)\n",
        "\n",
        "# Labels: Fake = 0, Real = 1\n",
        "fake_valid_labels = [0] * len(fake_valid_landmarks)\n",
        "real_valid_labels = [1] * len(real_valid_landmarks)\n",
        "\n",
        "# Load spatial features from pickle files\n",
        "print(\"Loading spatial features...\")\n",
        "with open('drive/MyDrive/SP_cup/features/spatial_valid_fake.pkl', 'rb') as f:\n",
        "    fake_spatial_features = pickle.load(f)\n",
        "\n",
        "with open('drive/MyDrive/SP_cup/features/spatial_valid_real.pkl', 'rb') as f:\n",
        "    real_spatial_features = pickle.load(f)\n",
        "\n",
        "# Combine facial landmarks and spatial features\n",
        "print(\"Combining facial landmarks and spatial features...\")\n",
        "\n",
        "# Function to ensure landmarks and spatial features are valid arrays\n",
        "def ensure_valid_array(data):\n",
        "    if isinstance(data, np.ndarray):\n",
        "        return data.flatten()  # Flatten the array to 1D\n",
        "    else:\n",
        "        return np.array(data).flatten()  # Ensure it's an array and flatten\n",
        "\n",
        "combined_features = []\n",
        "\n",
        "# Combine features for fake images\n",
        "for lm, spatial in zip(fake_valid_landmarks, fake_spatial_features):\n",
        "    if lm is not None and spatial is not None:\n",
        "        lm = ensure_valid_array(lm)\n",
        "        spatial = spatial.get('features', None)  # Extract the features array from the dictionary\n",
        "        if spatial is not None:\n",
        "            spatial = ensure_valid_array(spatial)\n",
        "            if len(lm) > 0 and len(spatial) > 0:\n",
        "                combined_features.append(np.concatenate([lm, spatial]))\n",
        "\n",
        "# Combine features for real images\n",
        "for lm, spatial in zip(real_valid_landmarks, real_spatial_features):\n",
        "    if lm is not None and spatial is not None:\n",
        "        lm = ensure_valid_array(lm)\n",
        "        spatial = spatial.get('features', None)  # Extract the features array from the dictionary\n",
        "        if spatial is not None:\n",
        "            spatial = ensure_valid_array(spatial)\n",
        "            if len(lm) > 0 and len(spatial) > 0:\n",
        "                combined_features.append(np.concatenate([lm, spatial]))\n",
        "\n",
        "# Convert to numpy array\n",
        "combined_features = np.array(combined_features, dtype=np.float32)\n",
        "\n",
        "# Combine labels\n",
        "combined_labels = np.array(fake_valid_labels + real_valid_labels, dtype=np.int32)\n",
        "\n",
        "# Resampling with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(combined_features, combined_labels)\n",
        "\n",
        "# Define the hyperparameters for XGBoost\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'booster': 'gbtree',\n",
        "    'max_depth': 5,  # You can tune this\n",
        "    'learning_rate': 0.1,  # You can tune this\n",
        "    'n_estimators': 100,  # You can tune this\n",
        "    'subsample': 0.8,  # You can tune this\n",
        "    'colsample_bytree': 0.8,  # You can tune this\n",
        "    'gamma': 0.1,  # You can tune this\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Prepare the DMatrix for XGBoost\n",
        "dtrain = xgb.DMatrix(X_resampled, label=y_resampled)\n",
        "\n",
        "# Perform Cross-validation with hyperparameter tuning\n",
        "cv_results = xgb.cv(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=200,\n",
        "    nfold=3,\n",
        "    metrics=['error', 'logloss'],\n",
        "    early_stopping_rounds=10,\n",
        "    verbose_eval=True\n",
        ")\n",
        "\n",
        "# Print the results\n",
        "print(\"Cross-validation results:\")\n",
        "print(cv_results)\n",
        "\n",
        "# Best iteration from cross-validation (based on evaluation metrics)\n",
        "best_iteration = cv_results['test-logloss-mean'].idxmin()\n",
        "\n",
        "# Train the final model using the best parameters\n",
        "final_model = xgb.train(params, dtrain, num_boost_round=best_iteration)\n",
        "\n",
        "# Save the final model\n",
        "joblib.dump(final_model, 'best_landmark_model.xgb')\n",
        "\n",
        "# Predict using the final model\n",
        "print(\"Predicting on validation data...\")\n",
        "y_pred = final_model.predict(xgb.DMatrix(X_resampled))\n",
        "y_pred = np.round(y_pred)  # Round to get binary predictions (0 or 1)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating model...\")\n",
        "print(classification_report(y_resampled, y_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_resampled, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbSiKoHFfVdc",
        "outputId": "9c42a63b-54f7-471f-ffda-35f9294dd10d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading facial landmarks...\n",
            "Loading spatial features...\n",
            "Combining facial landmarks and spatial features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:24:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:24:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:24:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-error:0.05311+0.00732\ttrain-logloss:0.61290+0.00068\ttest-error:0.09068+0.01443\ttest-logloss:0.61963+0.00052\n",
            "[1]\ttrain-error:0.04064+0.00914\ttrain-logloss:0.54995+0.00146\ttest-error:0.07189+0.00439\ttest-logloss:0.56113+0.00080\n",
            "[2]\ttrain-error:0.03158+0.00728\ttrain-logloss:0.49733+0.00233\ttest-error:0.06315+0.00479\ttest-logloss:0.51285+0.00214\n",
            "[3]\ttrain-error:0.03174+0.00471\ttrain-logloss:0.45024+0.00239\ttest-error:0.05893+0.01252\ttest-logloss:0.46848+0.00362\n",
            "[4]\ttrain-error:0.02445+0.00679\ttrain-logloss:0.40714+0.00231\ttest-error:0.05505+0.00910\ttest-logloss:0.42892+0.00351\n",
            "[5]\ttrain-error:0.02348+0.00309\ttrain-logloss:0.37140+0.00207\ttest-error:0.05505+0.00681\ttest-logloss:0.39669+0.00341\n",
            "[6]\ttrain-error:0.02364+0.00256\ttrain-logloss:0.33903+0.00170\ttest-error:0.05602+0.00643\ttest-logloss:0.36637+0.00326\n",
            "[7]\ttrain-error:0.02008+0.00375\ttrain-logloss:0.31108+0.00203\ttest-error:0.05019+0.00797\ttest-logloss:0.34107+0.00389\n",
            "[8]\ttrain-error:0.01976+0.00527\ttrain-logloss:0.28715+0.00212\ttest-error:0.05246+0.00960\ttest-logloss:0.31964+0.00469\n",
            "[9]\ttrain-error:0.01749+0.00300\ttrain-logloss:0.26482+0.00171\ttest-error:0.04987+0.00839\ttest-logloss:0.30011+0.00492\n",
            "[10]\ttrain-error:0.01635+0.00499\ttrain-logloss:0.24490+0.00251\ttest-error:0.04825+0.00875\ttest-logloss:0.28242+0.00452\n",
            "[11]\ttrain-error:0.01457+0.00418\ttrain-logloss:0.22646+0.00255\ttest-error:0.04631+0.00769\ttest-logloss:0.26631+0.00501\n",
            "[12]\ttrain-error:0.01295+0.00369\ttrain-logloss:0.21012+0.00227\ttest-error:0.04598+0.00682\ttest-logloss:0.25167+0.00533\n",
            "[13]\ttrain-error:0.01231+0.00369\ttrain-logloss:0.19541+0.00177\ttest-error:0.04177+0.00871\ttest-logloss:0.23896+0.00558\n",
            "[14]\ttrain-error:0.01166+0.00346\ttrain-logloss:0.18144+0.00203\ttest-error:0.04242+0.00769\ttest-logloss:0.22618+0.00613\n",
            "[15]\ttrain-error:0.01117+0.00414\ttrain-logloss:0.16928+0.00194\ttest-error:0.04112+0.00813\ttest-logloss:0.21531+0.00644\n",
            "[16]\ttrain-error:0.01004+0.00255\ttrain-logloss:0.15796+0.00236\ttest-error:0.04015+0.00782\ttest-logloss:0.20485+0.00688\n",
            "[17]\ttrain-error:0.00874+0.00206\ttrain-logloss:0.14733+0.00250\ttest-error:0.03789+0.00686\ttest-logloss:0.19504+0.00645\n",
            "[18]\ttrain-error:0.00761+0.00200\ttrain-logloss:0.13747+0.00257\ttest-error:0.03724+0.00584\ttest-logloss:0.18564+0.00690\n",
            "[19]\ttrain-error:0.00729+0.00198\ttrain-logloss:0.12838+0.00267\ttest-error:0.03595+0.00363\ttest-logloss:0.17754+0.00715\n",
            "[20]\ttrain-error:0.00648+0.00100\ttrain-logloss:0.12051+0.00254\ttest-error:0.03400+0.00442\ttest-logloss:0.17014+0.00787\n",
            "[21]\ttrain-error:0.00534+0.00079\ttrain-logloss:0.11303+0.00267\ttest-error:0.03303+0.00397\ttest-logloss:0.16380+0.00809\n",
            "[22]\ttrain-error:0.00437+0.00069\ttrain-logloss:0.10646+0.00236\ttest-error:0.03271+0.00452\ttest-logloss:0.15728+0.00913\n",
            "[23]\ttrain-error:0.00372+0.00061\ttrain-logloss:0.10003+0.00246\ttest-error:0.02979+0.00438\ttest-logloss:0.15156+0.00897\n",
            "[24]\ttrain-error:0.00389+0.00105\ttrain-logloss:0.09421+0.00227\ttest-error:0.02947+0.00256\ttest-logloss:0.14607+0.00888\n",
            "[25]\ttrain-error:0.00340+0.00105\ttrain-logloss:0.08886+0.00194\ttest-error:0.02817+0.00413\ttest-logloss:0.14089+0.00942\n",
            "[26]\ttrain-error:0.00291+0.00040\ttrain-logloss:0.08355+0.00200\ttest-error:0.02720+0.00364\ttest-logloss:0.13569+0.00919\n",
            "[27]\ttrain-error:0.00275+0.00061\ttrain-logloss:0.07866+0.00185\ttest-error:0.02623+0.00318\ttest-logloss:0.13111+0.00971\n",
            "[28]\ttrain-error:0.00227+0.00046\ttrain-logloss:0.07417+0.00182\ttest-error:0.02591+0.00301\ttest-logloss:0.12763+0.01032\n",
            "[29]\ttrain-error:0.00211+0.00061\ttrain-logloss:0.07014+0.00197\ttest-error:0.02591+0.00301\ttest-logloss:0.12390+0.01059\n",
            "[30]\ttrain-error:0.00178+0.00046\ttrain-logloss:0.06624+0.00212\ttest-error:0.02591+0.00376\ttest-logloss:0.12050+0.01078\n",
            "[31]\ttrain-error:0.00162+0.00023\ttrain-logloss:0.06265+0.00200\ttest-error:0.02429+0.00420\ttest-logloss:0.11666+0.01106\n",
            "[32]\ttrain-error:0.00178+0.00046\ttrain-logloss:0.05924+0.00186\ttest-error:0.02429+0.00364\ttest-logloss:0.11350+0.01164\n",
            "[33]\ttrain-error:0.00146+0.00040\ttrain-logloss:0.05616+0.00182\ttest-error:0.02364+0.00459\ttest-logloss:0.11016+0.01189\n",
            "[34]\ttrain-error:0.00113+0.00023\ttrain-logloss:0.05359+0.00179\ttest-error:0.02299+0.00452\ttest-logloss:0.10732+0.01211\n",
            "[35]\ttrain-error:0.00097+0.00000\ttrain-logloss:0.05085+0.00179\ttest-error:0.02202+0.00479\ttest-logloss:0.10418+0.01224\n",
            "[36]\ttrain-error:0.00081+0.00023\ttrain-logloss:0.04829+0.00186\ttest-error:0.02170+0.00517\ttest-logloss:0.10104+0.01210\n",
            "[37]\ttrain-error:0.00049+0.00000\ttrain-logloss:0.04583+0.00173\ttest-error:0.02105+0.00517\ttest-logloss:0.09836+0.01201\n",
            "[38]\ttrain-error:0.00049+0.00000\ttrain-logloss:0.04367+0.00169\ttest-error:0.02073+0.00517\ttest-logloss:0.09577+0.01186\n",
            "[39]\ttrain-error:0.00049+0.00000\ttrain-logloss:0.04161+0.00163\ttest-error:0.02105+0.00479\ttest-logloss:0.09360+0.01251\n",
            "[40]\ttrain-error:0.00049+0.00000\ttrain-logloss:0.03972+0.00172\ttest-error:0.02137+0.00477\ttest-logloss:0.09153+0.01229\n",
            "[41]\ttrain-error:0.00032+0.00023\ttrain-logloss:0.03783+0.00164\ttest-error:0.02008+0.00400\ttest-logloss:0.08909+0.01215\n",
            "[42]\ttrain-error:0.00032+0.00023\ttrain-logloss:0.03614+0.00147\ttest-error:0.01943+0.00397\ttest-logloss:0.08700+0.01217\n",
            "[43]\ttrain-error:0.00032+0.00023\ttrain-logloss:0.03445+0.00143\ttest-error:0.02008+0.00438\ttest-logloss:0.08481+0.01216\n",
            "[44]\ttrain-error:0.00032+0.00023\ttrain-logloss:0.03297+0.00135\ttest-error:0.01911+0.00400\ttest-logloss:0.08288+0.01242\n",
            "[45]\ttrain-error:0.00032+0.00023\ttrain-logloss:0.03161+0.00125\ttest-error:0.01911+0.00438\ttest-logloss:0.08096+0.01236\n",
            "[46]\ttrain-error:0.00032+0.00023\ttrain-logloss:0.03028+0.00131\ttest-error:0.01846+0.00442\ttest-logloss:0.07983+0.01242\n",
            "[47]\ttrain-error:0.00032+0.00023\ttrain-logloss:0.02907+0.00122\ttest-error:0.01976+0.00479\ttest-logloss:0.07837+0.01235\n",
            "[48]\ttrain-error:0.00032+0.00023\ttrain-logloss:0.02788+0.00115\ttest-error:0.01878+0.00438\ttest-logloss:0.07720+0.01205\n",
            "[49]\ttrain-error:0.00032+0.00023\ttrain-logloss:0.02672+0.00103\ttest-error:0.01846+0.00364\ttest-logloss:0.07576+0.01228\n",
            "[50]\ttrain-error:0.00032+0.00023\ttrain-logloss:0.02560+0.00102\ttest-error:0.01846+0.00442\ttest-logloss:0.07412+0.01265\n",
            "[51]\ttrain-error:0.00016+0.00023\ttrain-logloss:0.02459+0.00098\ttest-error:0.01814+0.00438\ttest-logloss:0.07266+0.01241\n",
            "[52]\ttrain-error:0.00016+0.00023\ttrain-logloss:0.02360+0.00094\ttest-error:0.01814+0.00517\ttest-logloss:0.07148+0.01241\n",
            "[53]\ttrain-error:0.00016+0.00023\ttrain-logloss:0.02268+0.00087\ttest-error:0.01781+0.00517\ttest-logloss:0.06991+0.01247\n",
            "[54]\ttrain-error:0.00016+0.00023\ttrain-logloss:0.02186+0.00085\ttest-error:0.01716+0.00479\ttest-logloss:0.06880+0.01255\n",
            "[55]\ttrain-error:0.00016+0.00023\ttrain-logloss:0.02112+0.00086\ttest-error:0.01749+0.00496\ttest-logloss:0.06797+0.01285\n",
            "[56]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.02039+0.00083\ttest-error:0.01652+0.00599\ttest-logloss:0.06691+0.01275\n",
            "[57]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01970+0.00081\ttest-error:0.01652+0.00573\ttest-logloss:0.06594+0.01283\n",
            "[58]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01901+0.00080\ttest-error:0.01619+0.00585\ttest-logloss:0.06472+0.01268\n",
            "[59]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01838+0.00078\ttest-error:0.01619+0.00606\ttest-logloss:0.06388+0.01311\n",
            "[60]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01775+0.00074\ttest-error:0.01522+0.00684\ttest-logloss:0.06275+0.01306\n",
            "[61]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01722+0.00074\ttest-error:0.01490+0.00694\ttest-logloss:0.06186+0.01310\n",
            "[62]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01666+0.00074\ttest-error:0.01490+0.00694\ttest-logloss:0.06139+0.01335\n",
            "[63]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01615+0.00071\ttest-error:0.01490+0.00694\ttest-logloss:0.06087+0.01353\n",
            "[64]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01566+0.00069\ttest-error:0.01555+0.00650\ttest-logloss:0.06035+0.01358\n",
            "[65]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01521+0.00067\ttest-error:0.01458+0.00727\ttest-logloss:0.05991+0.01383\n",
            "[66]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01476+0.00066\ttest-error:0.01425+0.00737\ttest-logloss:0.05935+0.01383\n",
            "[67]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01432+0.00064\ttest-error:0.01393+0.00750\ttest-logloss:0.05883+0.01387\n",
            "[68]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01390+0.00060\ttest-error:0.01425+0.00737\ttest-logloss:0.05834+0.01404\n",
            "[69]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01352+0.00061\ttest-error:0.01425+0.00737\ttest-logloss:0.05789+0.01411\n",
            "[70]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01316+0.00061\ttest-error:0.01457+0.00706\ttest-logloss:0.05734+0.01432\n",
            "[71]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01283+0.00061\ttest-error:0.01425+0.00737\ttest-logloss:0.05681+0.01445\n",
            "[72]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01248+0.00056\ttest-error:0.01458+0.00727\ttest-logloss:0.05626+0.01440\n",
            "[73]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01219+0.00055\ttest-error:0.01490+0.00675\ttest-logloss:0.05593+0.01463\n",
            "[74]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01186+0.00055\ttest-error:0.01458+0.00727\ttest-logloss:0.05560+0.01479\n",
            "[75]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01157+0.00052\ttest-error:0.01490+0.00694\ttest-logloss:0.05536+0.01486\n",
            "[76]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01130+0.00052\ttest-error:0.01458+0.00757\ttest-logloss:0.05485+0.01486\n",
            "[77]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01103+0.00051\ttest-error:0.01393+0.00771\ttest-logloss:0.05429+0.01493\n",
            "[78]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01076+0.00049\ttest-error:0.01490+0.00720\ttest-logloss:0.05403+0.01488\n",
            "[79]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01052+0.00049\ttest-error:0.01457+0.00706\ttest-logloss:0.05359+0.01484\n",
            "[80]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01029+0.00049\ttest-error:0.01393+0.00737\ttest-logloss:0.05311+0.01488\n",
            "[81]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.01007+0.00047\ttest-error:0.01490+0.00675\ttest-logloss:0.05272+0.01456\n",
            "[82]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00986+0.00047\ttest-error:0.01457+0.00630\ttest-logloss:0.05240+0.01454\n",
            "[83]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00964+0.00044\ttest-error:0.01490+0.00675\ttest-logloss:0.05201+0.01458\n",
            "[84]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00943+0.00043\ttest-error:0.01457+0.00706\ttest-logloss:0.05173+0.01468\n",
            "[85]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00924+0.00043\ttest-error:0.01393+0.00666\ttest-logloss:0.05131+0.01471\n",
            "[86]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00905+0.00042\ttest-error:0.01425+0.00646\ttest-logloss:0.05120+0.01491\n",
            "[87]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00887+0.00043\ttest-error:0.01393+0.00601\ttest-logloss:0.05093+0.01488\n",
            "[88]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00870+0.00041\ttest-error:0.01393+0.00596\ttest-logloss:0.05044+0.01485\n",
            "[89]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00853+0.00040\ttest-error:0.01360+0.00620\ttest-logloss:0.05018+0.01482\n",
            "[90]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00837+0.00039\ttest-error:0.01393+0.00601\ttest-logloss:0.04991+0.01474\n",
            "[91]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00822+0.00038\ttest-error:0.01393+0.00666\ttest-logloss:0.04978+0.01490\n",
            "[92]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00805+0.00038\ttest-error:0.01360+0.00620\ttest-logloss:0.04944+0.01511\n",
            "[93]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00789+0.00038\ttest-error:0.01360+0.00620\ttest-logloss:0.04924+0.01510\n",
            "[94]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00775+0.00037\ttest-error:0.01360+0.00620\ttest-logloss:0.04875+0.01520\n",
            "[95]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00762+0.00038\ttest-error:0.01360+0.00620\ttest-logloss:0.04847+0.01512\n",
            "[96]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00749+0.00037\ttest-error:0.01328+0.00646\ttest-logloss:0.04824+0.01519\n",
            "[97]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00737+0.00038\ttest-error:0.01360+0.00692\ttest-logloss:0.04799+0.01517\n",
            "[98]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00724+0.00038\ttest-error:0.01328+0.00646\ttest-logloss:0.04788+0.01520\n",
            "[99]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00712+0.00038\ttest-error:0.01393+0.00666\ttest-logloss:0.04766+0.01524\n",
            "[100]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00701+0.00038\ttest-error:0.01360+0.00692\ttest-logloss:0.04737+0.01517\n",
            "[101]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00690+0.00038\ttest-error:0.01393+0.00666\ttest-logloss:0.04725+0.01520\n",
            "[102]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00679+0.00037\ttest-error:0.01393+0.00666\ttest-logloss:0.04710+0.01527\n",
            "[103]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00667+0.00036\ttest-error:0.01360+0.00692\ttest-logloss:0.04695+0.01531\n",
            "[104]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00658+0.00036\ttest-error:0.01360+0.00692\ttest-logloss:0.04671+0.01521\n",
            "[105]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00649+0.00035\ttest-error:0.01360+0.00687\ttest-logloss:0.04654+0.01515\n",
            "[106]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00639+0.00034\ttest-error:0.01457+0.00692\ttest-logloss:0.04641+0.01515\n",
            "[107]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00631+0.00033\ttest-error:0.01360+0.00687\ttest-logloss:0.04620+0.01519\n",
            "[108]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00622+0.00033\ttest-error:0.01296+0.00666\ttest-logloss:0.04610+0.01517\n",
            "[109]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00613+0.00032\ttest-error:0.01328+0.00711\ttest-logloss:0.04600+0.01528\n",
            "[110]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00604+0.00031\ttest-error:0.01296+0.00666\ttest-logloss:0.04574+0.01529\n",
            "[111]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00597+0.00030\ttest-error:0.01296+0.00666\ttest-logloss:0.04562+0.01528\n",
            "[112]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00588+0.00030\ttest-error:0.01296+0.00666\ttest-logloss:0.04540+0.01542\n",
            "[113]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00581+0.00030\ttest-error:0.01296+0.00666\ttest-logloss:0.04535+0.01541\n",
            "[114]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00574+0.00029\ttest-error:0.01296+0.00666\ttest-logloss:0.04525+0.01549\n",
            "[115]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00566+0.00028\ttest-error:0.01296+0.00666\ttest-logloss:0.04519+0.01553\n",
            "[116]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00558+0.00028\ttest-error:0.01328+0.00646\ttest-logloss:0.04502+0.01558\n",
            "[117]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00552+0.00028\ttest-error:0.01328+0.00646\ttest-logloss:0.04492+0.01564\n",
            "[118]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00544+0.00028\ttest-error:0.01328+0.00646\ttest-logloss:0.04487+0.01576\n",
            "[119]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00537+0.00028\ttest-error:0.01328+0.00574\ttest-logloss:0.04474+0.01566\n",
            "[120]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00530+0.00027\ttest-error:0.01328+0.00646\ttest-logloss:0.04467+0.01584\n",
            "[121]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00523+0.00026\ttest-error:0.01296+0.00601\ttest-logloss:0.04451+0.01588\n",
            "[122]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00517+0.00026\ttest-error:0.01263+0.00620\ttest-logloss:0.04437+0.01581\n",
            "[123]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00511+0.00026\ttest-error:0.01328+0.00642\ttest-logloss:0.04431+0.01580\n",
            "[124]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00506+0.00026\ttest-error:0.01360+0.00620\ttest-logloss:0.04423+0.01586\n",
            "[125]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00500+0.00026\ttest-error:0.01328+0.00642\ttest-logloss:0.04416+0.01592\n",
            "[126]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00495+0.00025\ttest-error:0.01328+0.00642\ttest-logloss:0.04403+0.01592\n",
            "[127]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00489+0.00025\ttest-error:0.01360+0.00687\ttest-logloss:0.04409+0.01598\n",
            "[128]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00485+0.00025\ttest-error:0.01328+0.00642\ttest-logloss:0.04407+0.01599\n",
            "[129]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00479+0.00025\ttest-error:0.01360+0.00620\ttest-logloss:0.04408+0.01603\n",
            "[130]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00474+0.00024\ttest-error:0.01328+0.00646\ttest-logloss:0.04404+0.01618\n",
            "[131]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00470+0.00025\ttest-error:0.01328+0.00646\ttest-logloss:0.04394+0.01618\n",
            "[132]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00465+0.00024\ttest-error:0.01296+0.00675\ttest-logloss:0.04381+0.01627\n",
            "[133]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00460+0.00024\ttest-error:0.01296+0.00675\ttest-logloss:0.04365+0.01628\n",
            "[134]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00456+0.00023\ttest-error:0.01263+0.00630\ttest-logloss:0.04360+0.01629\n",
            "[135]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00452+0.00023\ttest-error:0.01296+0.00675\ttest-logloss:0.04356+0.01624\n",
            "[136]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00447+0.00023\ttest-error:0.01296+0.00675\ttest-logloss:0.04346+0.01626\n",
            "[137]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00442+0.00023\ttest-error:0.01296+0.00675\ttest-logloss:0.04335+0.01626\n",
            "[138]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00438+0.00023\ttest-error:0.01263+0.00630\ttest-logloss:0.04327+0.01630\n",
            "[139]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00433+0.00023\ttest-error:0.01263+0.00630\ttest-logloss:0.04311+0.01625\n",
            "[140]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00429+0.00022\ttest-error:0.01198+0.00540\ttest-logloss:0.04306+0.01628\n",
            "[141]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00425+0.00022\ttest-error:0.01231+0.00585\ttest-logloss:0.04290+0.01620\n",
            "[142]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00421+0.00021\ttest-error:0.01231+0.00585\ttest-logloss:0.04281+0.01637\n",
            "[143]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00417+0.00021\ttest-error:0.01231+0.00585\ttest-logloss:0.04266+0.01631\n",
            "[144]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00414+0.00021\ttest-error:0.01231+0.00585\ttest-logloss:0.04256+0.01634\n",
            "[145]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00411+0.00021\ttest-error:0.01231+0.00585\ttest-logloss:0.04256+0.01639\n",
            "[146]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00407+0.00021\ttest-error:0.01231+0.00585\ttest-logloss:0.04250+0.01627\n",
            "[147]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00404+0.00020\ttest-error:0.01198+0.00601\ttest-logloss:0.04239+0.01632\n",
            "[148]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00401+0.00020\ttest-error:0.01198+0.00601\ttest-logloss:0.04243+0.01642\n",
            "[149]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00398+0.00020\ttest-error:0.01198+0.00601\ttest-logloss:0.04237+0.01644\n",
            "[150]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00395+0.00020\ttest-error:0.01231+0.00585\ttest-logloss:0.04230+0.01639\n",
            "[151]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00392+0.00020\ttest-error:0.01231+0.00574\ttest-logloss:0.04231+0.01647\n",
            "[152]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00389+0.00020\ttest-error:0.01231+0.00574\ttest-logloss:0.04227+0.01645\n",
            "[153]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00385+0.00020\ttest-error:0.01198+0.00601\ttest-logloss:0.04222+0.01657\n",
            "[154]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00382+0.00019\ttest-error:0.01198+0.00601\ttest-logloss:0.04222+0.01668\n",
            "[155]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00379+0.00019\ttest-error:0.01198+0.00601\ttest-logloss:0.04213+0.01657\n",
            "[156]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00376+0.00019\ttest-error:0.01263+0.00620\ttest-logloss:0.04199+0.01659\n",
            "[157]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00373+0.00019\ttest-error:0.01263+0.00620\ttest-logloss:0.04197+0.01658\n",
            "[158]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00370+0.00019\ttest-error:0.01231+0.00574\ttest-logloss:0.04183+0.01661\n",
            "[159]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00368+0.00019\ttest-error:0.01263+0.00620\ttest-logloss:0.04183+0.01663\n",
            "[160]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00365+0.00019\ttest-error:0.01295+0.00596\ttest-logloss:0.04178+0.01663\n",
            "[161]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00363+0.00018\ttest-error:0.01295+0.00596\ttest-logloss:0.04165+0.01662\n",
            "[162]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00360+0.00018\ttest-error:0.01263+0.00620\ttest-logloss:0.04162+0.01670\n",
            "[163]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00358+0.00018\ttest-error:0.01296+0.00601\ttest-logloss:0.04159+0.01668\n",
            "[164]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00356+0.00018\ttest-error:0.01263+0.00556\ttest-logloss:0.04147+0.01671\n",
            "[165]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00354+0.00018\ttest-error:0.01263+0.00556\ttest-logloss:0.04140+0.01665\n",
            "[166]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00351+0.00018\ttest-error:0.01263+0.00620\ttest-logloss:0.04126+0.01669\n",
            "[167]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00349+0.00018\ttest-error:0.01263+0.00620\ttest-logloss:0.04111+0.01667\n",
            "[168]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00347+0.00018\ttest-error:0.01263+0.00620\ttest-logloss:0.04111+0.01673\n",
            "[169]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00344+0.00018\ttest-error:0.01263+0.00620\ttest-logloss:0.04114+0.01678\n",
            "[170]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00342+0.00017\ttest-error:0.01231+0.00574\ttest-logloss:0.04112+0.01677\n",
            "[171]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00340+0.00017\ttest-error:0.01231+0.00574\ttest-logloss:0.04112+0.01676\n",
            "[172]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00338+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04105+0.01669\n",
            "[173]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00335+0.00017\ttest-error:0.01231+0.00574\ttest-logloss:0.04098+0.01662\n",
            "[174]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00333+0.00017\ttest-error:0.01231+0.00574\ttest-logloss:0.04092+0.01664\n",
            "[175]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00331+0.00016\ttest-error:0.01263+0.00620\ttest-logloss:0.04088+0.01671\n",
            "[176]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00330+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04075+0.01672\n",
            "[177]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00328+0.00017\ttest-error:0.01263+0.00620\ttest-logloss:0.04074+0.01675\n",
            "[178]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00326+0.00017\ttest-error:0.01231+0.00574\ttest-logloss:0.04074+0.01684\n",
            "[179]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00324+0.00017\ttest-error:0.01263+0.00620\ttest-logloss:0.04069+0.01690\n",
            "[180]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00322+0.00017\ttest-error:0.01231+0.00574\ttest-logloss:0.04066+0.01689\n",
            "[181]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00320+0.00017\ttest-error:0.01231+0.00574\ttest-logloss:0.04066+0.01697\n",
            "[182]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00318+0.00017\ttest-error:0.01231+0.00574\ttest-logloss:0.04067+0.01699\n",
            "[183]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00317+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04069+0.01702\n",
            "[184]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00315+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04057+0.01690\n",
            "[185]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00313+0.00016\ttest-error:0.01198+0.00601\ttest-logloss:0.04057+0.01695\n",
            "[186]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00312+0.00016\ttest-error:0.01198+0.00601\ttest-logloss:0.04048+0.01695\n",
            "[187]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00310+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04046+0.01702\n",
            "[188]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00309+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04039+0.01696\n",
            "[189]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00307+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04035+0.01688\n",
            "[190]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00305+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04034+0.01688\n",
            "[191]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00303+0.00015\ttest-error:0.01231+0.00574\ttest-logloss:0.04033+0.01692\n",
            "[192]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00301+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04033+0.01695\n",
            "[193]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00300+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04022+0.01696\n",
            "[194]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00298+0.00015\ttest-error:0.01198+0.00601\ttest-logloss:0.04023+0.01699\n",
            "[195]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00297+0.00015\ttest-error:0.01231+0.00574\ttest-logloss:0.04029+0.01711\n",
            "[196]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00295+0.00015\ttest-error:0.01231+0.00574\ttest-logloss:0.04032+0.01716\n",
            "[197]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00294+0.00015\ttest-error:0.01231+0.00574\ttest-logloss:0.04033+0.01715\n",
            "[198]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00293+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04024+0.01716\n",
            "[199]\ttrain-error:0.00000+0.00000\ttrain-logloss:0.00291+0.00016\ttest-error:0.01231+0.00574\ttest-logloss:0.04023+0.01720\n",
            "Cross-validation results:\n",
            "     train-error-mean  train-error-std  train-logloss-mean  train-logloss-std  \\\n",
            "0            0.053109         0.007318            0.612901           0.000681   \n",
            "1            0.040643         0.009144            0.549950           0.001457   \n",
            "2            0.031575         0.007278            0.497328           0.002327   \n",
            "3            0.031737         0.004706            0.450245           0.002389   \n",
            "4            0.024451         0.006788            0.407137           0.002307   \n",
            "..                ...              ...                 ...                ...   \n",
            "195          0.000000         0.000000            0.002968           0.000154   \n",
            "196          0.000000         0.000000            0.002954           0.000154   \n",
            "197          0.000000         0.000000            0.002941           0.000155   \n",
            "198          0.000000         0.000000            0.002925           0.000156   \n",
            "199          0.000000         0.000000            0.002911           0.000156   \n",
            "\n",
            "     test-error-mean  test-error-std  test-logloss-mean  test-logloss-std  \n",
            "0           0.090680        0.014430           0.619631          0.000518  \n",
            "1           0.071890        0.004391           0.561135          0.000802  \n",
            "2           0.063145        0.004795           0.512851          0.002139  \n",
            "3           0.058932        0.012522           0.468484          0.003618  \n",
            "4           0.055048        0.009102           0.428915          0.003513  \n",
            "..               ...             ...                ...               ...  \n",
            "195         0.012307        0.005742           0.040293          0.017114  \n",
            "196         0.012307        0.005742           0.040318          0.017163  \n",
            "197         0.012307        0.005742           0.040329          0.017155  \n",
            "198         0.012307        0.005742           0.040240          0.017159  \n",
            "199         0.012307        0.005742           0.040231          0.017202  \n",
            "\n",
            "[200 rows x 8 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:25:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting on validation data...\n",
            "Evaluating model...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1544\n",
            "           1       1.00      1.00      1.00      1544\n",
            "\n",
            "    accuracy                           1.00      3088\n",
            "   macro avg       1.00      1.00      1.00      3088\n",
            "weighted avg       1.00      1.00      1.00      3088\n",
            "\n",
            "Validation Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the trained model\n",
        "print(\"Loading the trained model...\")\n",
        "model = joblib.load('best_landmark_model.xgb')\n",
        "\n",
        "# Load spatial features from pickle files for testing\n",
        "print(\"Loading spatial features for testing...\")\n",
        "\n",
        "with open('drive/MyDrive/SP_cup/features/spatial_valid_fake.pkl', 'rb') as f:\n",
        "    fake_spatial_features = pickle.load(f)\n",
        "\n",
        "with open('drive/MyDrive/SP_cup/features/spatial_valid_real.pkl', 'rb') as f:\n",
        "    real_spatial_features = pickle.load(f)\n",
        "\n",
        "# Function to ensure spatial features are valid arrays\n",
        "def ensure_valid_array(data):\n",
        "    if isinstance(data, np.ndarray):\n",
        "        return data.flatten()  # Flatten the array to 1D\n",
        "    else:\n",
        "        return np.array(data).flatten()  # Ensure it's an array and flatten\n",
        "\n",
        "combined_features = []\n",
        "\n",
        "# Combine features for fake images\n",
        "for spatial in fake_spatial_features:\n",
        "    if spatial is not None:\n",
        "        spatial = spatial.get('features', None)  # Extract the features array from the dictionary\n",
        "        if spatial is not None:\n",
        "            spatial = ensure_valid_array(spatial)\n",
        "            if len(spatial) > 0:\n",
        "                combined_features.append(spatial)\n",
        "\n",
        "# Combine features for real images\n",
        "for spatial in real_spatial_features:\n",
        "    if spatial is not None:\n",
        "        spatial = spatial.get('features', None)  # Extract the features array from the dictionary\n",
        "        if spatial is not None:\n",
        "            spatial = ensure_valid_array(spatial)\n",
        "            if len(spatial) > 0:\n",
        "                combined_features.append(spatial)\n",
        "\n",
        "# Convert to numpy array\n",
        "combined_features = np.array(combined_features, dtype=np.float32)\n",
        "\n",
        "# Prepare the DMatrix for prediction\n",
        "dtest = xgb.DMatrix(combined_features)\n",
        "\n",
        "# Predict using the trained model\n",
        "print(\"Predicting on test data...\")\n",
        "y_pred = model.predict(dtest)\n",
        "y_pred = np.round(y_pred)  # Round to get binary predictions (0 or 1)\n",
        "\n",
        "# Prepare labels (Fake = 0, Real = 1)\n",
        "y_true = [0] * len(fake_spatial_features) + [1] * len(real_spatial_features)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating model...\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOddtPz9h8Vi",
        "outputId": "56508968-b2fd-42f5-82a1-dd5ab9e198d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the trained model...\n",
            "Loading spatial features for testing...\n",
            "Predicting on test data...\n",
            "Evaluating model...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.00      1524\n",
            "           1       0.50      1.00      0.67      1548\n",
            "\n",
            "    accuracy                           0.50      3072\n",
            "   macro avg       0.59      0.50      0.34      3072\n",
            "weighted avg       0.58      0.50      0.34      3072\n",
            "\n",
            "Test Accuracy: 0.5042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the number of images matches with spatial features\n",
        "assert len(real_valid_image_paths) == len(real_spatial_features), \"Mismatch between image paths and spatial features\"\n",
        "\n",
        "# Extract image names from real valid image paths for comparison\n",
        "landmark_image_names = [image_path.split('/')[-1] for image_path in real_valid_image_paths]\n",
        "\n",
        "# Now map each spatial feature to its corresponding image name\n",
        "spatial_image_names = [image_path.split('/')[-1] for image_path in real_valid_image_paths]\n",
        "\n",
        "# Check for mismatch in image names\n",
        "mismatch_images = [(landmark_image_names[i], spatial_image_names[i]) for i in range(len(landmark_image_names)) if landmark_image_names[i] != spatial_image_names[i]]\n",
        "\n",
        "if mismatch_images:\n",
        "    print(f\"Mismatched image names: {mismatch_images[:5]}\")  # Show the first 5 mismatches\n",
        "else:\n",
        "    print(\"No mismatch in image names\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPNfRJWGSGdD",
        "outputId": "92ac21a0-d180-4cab-93a3-9068865951a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No mismatch in image names\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the structure of landmarks\n",
        "print(f\"Type of first fake landmark: {type(fake_valid_landmarks[0])}\")\n",
        "print(f\"First fake landmark: {fake_valid_landmarks[0]}\")\n",
        "\n",
        "# Similarly for spatial features\n",
        "print(f\"Type of first fake spatial feature: {type(fake_spatial_features[0])}\")\n",
        "print(f\"First fake spatial feature: {fake_spatial_features[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JfchHBDaSv6",
        "outputId": "b8633e3e-9c98-4717-e1f4-b39469e57149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of first fake landmark: <class 'numpy.ndarray'>\n",
            "First fake landmark: [ 32 121  34 142  36 163  40 183  51 200  67 214  87 224 108 231 127 232\n",
            " 141 228 152 218 160 204 166 189 171 173 173 157 175 142 175 126  67 116\n",
            "  79 108  94 104 110 104 124 108 139 109 149 105 160 105 169 108 174 116\n",
            " 133 122 134 134 136 147 138 159 119 167 126 169 134 171 139 169 144 167\n",
            "  85 125  93 122 101 121 108 125 101 127  93 127 143 125 150 122 157 123\n",
            " 162 125 157 128 150 128 102 191 115 187 126 186 131 187 136 186 141 187\n",
            " 145 191 141 195 137 197 131 198 125 198 115 196 107 191 125 191 131 191\n",
            " 136 191 142 191 136 190 131 190 125 190]\n",
            "Type of first fake spatial feature: <class 'dict'>\n",
            "First fake spatial feature: {'image_name': 'drive/MyDrive/validation/fake_valid/fake/valid_fake_0110265.png', 'features': array([-0.1473,  0.3027, -0.0877, ...,  0.128 , -0.0487,  0.1984],\n",
            "      dtype=float16)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QVLpFhAyjINS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}